{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9f7c72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:41:14.566554Z",
     "iopub.status.busy": "2025-11-01T15:41:14.566244Z",
     "iopub.status.idle": "2025-11-01T15:41:15.945277Z",
     "shell.execute_reply": "2025-11-01T15:41:15.944463Z"
    },
    "papermill": {
     "duration": 1.383824,
     "end_time": "2025-11-01T15:41:15.946656",
     "exception": false,
     "start_time": "2025-11-01T15:41:14.562832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Summary ===\n",
      "Rows: 1000, Cols: 30, Positive rate (Is_Delayed): 0.572\n",
      "Saved: df_working.csv\n"
     ]
    }
   ],
   "source": [
    "# === Block 1: Setup, ingest, target, quick summary ===\n",
    "import warnings, os, json, math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"/kaggle/input/bim-ai-integrated-dataset/bim_ai_civil_engineering_dataset.csv\"\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Parse dates if present\n",
    "for col in [\"Start_Date\", \"End_Date\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "# Basic hygiene\n",
    "if \"Planned_Duration\" not in df.columns or \"Actual_Duration\" not in df.columns:\n",
    "    raise ValueError(\"Missing Planned_Duration or Actual_Duration in dataset.\")\n",
    "df = df[df[\"Planned_Duration\"] > 0].copy()\n",
    "\n",
    "# Target (15% schedule overrun)\n",
    "df[\"Delay_Ratio\"] = df[\"Actual_Duration\"] / df[\"Planned_Duration\"] - 1.0\n",
    "df[\"Is_Delayed\"] = (df[\"Delay_Ratio\"] > 0.15).astype(int)\n",
    "\n",
    "# Summary\n",
    "n_rows, n_cols = df.shape\n",
    "pos_rate = df[\"Is_Delayed\"].mean()\n",
    "print(\"=== Data Summary ===\")\n",
    "print(f\"Rows: {n_rows}, Cols: {n_cols}, Positive rate (Is_Delayed): {pos_rate:.3f}\")\n",
    "\n",
    "# Keep a lightweight id column for later joins/exports\n",
    "if \"Project_ID\" not in df.columns:\n",
    "    df[\"Project_ID\"] = [f\"PJT_{i+1}\" for i in range(len(df))]\n",
    "\n",
    "# Save a working copy for later blocks\n",
    "df.to_csv(\"df_working.csv\", index=False)\n",
    "print(\"Saved: df_working.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cf71d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:41:15.952444Z",
     "iopub.status.busy": "2025-11-01T15:41:15.952011Z",
     "iopub.status.idle": "2025-11-01T15:41:17.466057Z",
     "shell.execute_reply": "2025-11-01T15:41:17.465452Z"
    },
    "papermill": {
     "duration": 1.51934,
     "end_time": "2025-11-01T15:41:17.468351",
     "exception": false,
     "start_time": "2025-11-01T15:41:15.949011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning Risk (component-calibrated) — ROC-AUC=0.475 | PR-AUC=0.568 | Brier=0.243\n",
      "Saved: brain_planning_v2_outputs.csv\n",
      "Saved: brain_planning_component_weights.json\n",
      "Saved: brain_planning_component_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# === Block 2: Planning Risk Index v2 (calibrated) ===\n",
    "import numpy as np, pandas as pd, json, joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "PATH = \"df_working.csv\"\n",
    "df = pd.read_csv(PATH, parse_dates=[\"Start_Date\",\"End_Date\"])\n",
    "\n",
    "# Helpers\n",
    "def nzstd(x): \n",
    "    x = x.astype(float)\n",
    "    return (x - x.mean())/(x.std()+1e-9)\n",
    "\n",
    "# Build 4 transparent components (planning/ex-ante only)\n",
    "comp = {}\n",
    "comp[\"resource\"] = 0\n",
    "if \"Labor_Hours\" in df:               comp[\"resource\"] += nzstd(df[\"Labor_Hours\"])\n",
    "if \"Equipment_Utilization\" in df:     comp[\"resource\"] += nzstd(df[\"Equipment_Utilization\"])\n",
    "if \"Material_Usage\" in df:            comp[\"resource\"] += nzstd(df[\"Material_Usage\"])\n",
    "\n",
    "comp[\"site_env\"] = 0\n",
    "for c in [\"Temperature\",\"Humidity\",\"Air_Quality_Index\"]:\n",
    "    if c in df: comp[\"site_env\"] += nzstd(df[c])\n",
    "\n",
    "comp[\"schedule\"] = 0\n",
    "if \"Planned_Duration\" in df:          comp[\"schedule\"] += nzstd(df[\"Planned_Duration\"])\n",
    "if \"Start_Date\" in df.columns:\n",
    "    s = pd.to_datetime(df[\"Start_Date\"], errors=\"coerce\")\n",
    "    comp[\"schedule\"] += ((s.dt.month - 6.5)/3.8).fillna(0)  # coarse seasonality\n",
    "\n",
    "comp[\"cost\"] = 0\n",
    "if {\"Planned_Cost\",\"Planned_Duration\"}.issubset(df.columns):\n",
    "    comp[\"cost\"] += nzstd(df[\"Planned_Cost\"]/df[\"Planned_Duration\"])\n",
    "\n",
    "COMP_DF = pd.DataFrame(comp).fillna(0.0)\n",
    "y = df[\"Is_Delayed\"].astype(int).values\n",
    "\n",
    "# Chronological split (80/20) if Start_Date exists; else index order\n",
    "if \"Start_Date\" in df.columns and pd.api.types.is_datetime64_any_dtype(df[\"Start_Date\"]):\n",
    "    order = df[\"Start_Date\"].rank(method=\"first\")\n",
    "else:\n",
    "    order = pd.Series(np.arange(len(df)))\n",
    "idx_sorted = order.sort_values().index\n",
    "split = int(0.8 * len(idx_sorted))\n",
    "tr_idx, te_idx = idx_sorted[:split], idx_sorted[split:]\n",
    "\n",
    "X_train, X_test = COMP_DF.loc[tr_idx].values, COMP_DF.loc[te_idx].values\n",
    "y_train, y_test = y[tr_idx], y[te_idx]\n",
    "\n",
    "# Calibrated logistic for probabilities (readable, stable)\n",
    "base = LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=42)\n",
    "clf = CalibratedClassifierCV(base, method=\"sigmoid\", cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "p_test = clf.predict_proba(X_test)[:,1]\n",
    "roc = roc_auc_score(y_test, p_test)\n",
    "pr  = average_precision_score(y_test, p_test)\n",
    "brier = brier_score_loss(y_test, p_test)\n",
    "print(f\"Planning Risk (component-calibrated) — ROC-AUC={roc:.3f} | PR-AUC={pr:.3f} | Brier={brier:.3f}\")\n",
    "\n",
    "# Full portfolio probabilities\n",
    "p_all = clf.predict_proba(COMP_DF.values)[:,1]\n",
    "\n",
    "out = pd.DataFrame({\n",
    "    \"Project_ID\": df[\"Project_ID\"],\n",
    "    \"comp_resource\": COMP_DF[\"resource\"],\n",
    "    \"comp_site_env\": COMP_DF[\"site_env\"],\n",
    "    \"comp_schedule\": COMP_DF[\"schedule\"],\n",
    "    \"comp_cost\":     COMP_DF[\"cost\"],\n",
    "    \"p_delay_planning\": p_all,\n",
    "})\n",
    "out[\"health_score_planning\"] = np.round(100*(1 - out[\"p_delay_planning\"])).astype(int)\n",
    "\n",
    "# Risk bands: quantiles on calibrated probabilities\n",
    "labels = [\"Low\",\"Medium\",\"High\"]\n",
    "try:\n",
    "    out[\"risk_band_planning\"] = pd.qcut(out[\"p_delay_planning\"], q=[0,0.33,0.66,1.0],\n",
    "                                        labels=labels, duplicates=\"drop\")\n",
    "except Exception:\n",
    "    cuts = [out[\"p_delay_planning\"].min()-1e-9,\n",
    "            out[\"p_delay_planning\"].quantile(0.33),\n",
    "            out[\"p_delay_planning\"].quantile(0.66),\n",
    "            out[\"p_delay_planning\"].max()+1e-9]\n",
    "    out[\"risk_band_planning\"] = pd.cut(out[\"p_delay_planning\"], bins=cuts, labels=labels, include_lowest=True)\n",
    "\n",
    "out.to_csv(\"brain_planning_v2_outputs.csv\", index=False)\n",
    "print(\"Saved: brain_planning_v2_outputs.csv\")\n",
    "\n",
    "# Human-readable global weights (auxiliary logistic without calibration)\n",
    "aux_lr = LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=42)\n",
    "aux_lr.fit(X_train, y_train)\n",
    "weights = dict(zip([\"resource\",\"site_env\",\"schedule\",\"cost\"], aux_lr.coef_[0].tolist()))\n",
    "intercept = float(aux_lr.intercept_[0])\n",
    "drivers = {\"component_weights\": weights, \"intercept\": intercept}\n",
    "json.dump(drivers, open(\"brain_planning_component_weights.json\",\"w\"), indent=2)\n",
    "print(\"Saved: brain_planning_component_weights.json\")\n",
    "\n",
    "# Save calibrated model bundle for what-if\n",
    "import joblib\n",
    "joblib.dump({\"calibrated_model\": clf}, \"brain_planning_component_model.pkl\")\n",
    "print(\"Saved: brain_planning_component_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fa83d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:41:17.478194Z",
     "iopub.status.busy": "2025-11-01T15:41:17.477959Z",
     "iopub.status.idle": "2025-11-01T15:41:17.522941Z",
     "shell.execute_reply": "2025-11-01T15:41:17.522310Z"
    },
    "papermill": {
     "duration": 0.052804,
     "end_time": "2025-11-01T15:41:17.524387",
     "exception": false,
     "start_time": "2025-11-01T15:41:17.471583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: planning_risk_index.csv\n"
     ]
    }
   ],
   "source": [
    "# === Block 3: Deterministic Planning Risk Index overlay ===\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"df_working.csv\", parse_dates=[\"Start_Date\",\"End_Date\"])\n",
    "\n",
    "def z(x):\n",
    "    x = x.astype(float)\n",
    "    return (x - x.mean())/(x.std()+1e-9)\n",
    "\n",
    "# Components (deterministic weights)\n",
    "w = {\"resource\":0.35, \"site_env\":0.25, \"schedule\":0.25, \"cost\":0.15}\n",
    "\n",
    "comp = {}\n",
    "t = 0\n",
    "if \"Labor_Hours\" in df:               t += z(df[\"Labor_Hours\"])\n",
    "if \"Equipment_Utilization\" in df:     t += z(df[\"Equipment_Utilization\"])\n",
    "if \"Material_Usage\" in df:            t += z(df[\"Material_Usage\"])\n",
    "comp[\"resource\"] = t\n",
    "\n",
    "t = 0\n",
    "for c in [\"Temperature\",\"Humidity\",\"Air_Quality_Index\"]:\n",
    "    if c in df: t += z(df[c])\n",
    "comp[\"site_env\"] = t\n",
    "\n",
    "t = 0\n",
    "if \"Planned_Duration\" in df:          t += z(df[\"Planned_Duration\"])\n",
    "if \"Start_Date\" in df.columns:\n",
    "    s = pd.to_datetime(df[\"Start_Date\"], errors=\"coerce\")\n",
    "    t += ((s.dt.month-6.5)/3.8).fillna(0)\n",
    "comp[\"schedule\"] = t\n",
    "\n",
    "t = 0\n",
    "if {\"Planned_Cost\",\"Planned_Duration\"}.issubset(df.columns):\n",
    "    t += z(df[\"Planned_Cost\"]/df[\"Planned_Duration\"])\n",
    "comp[\"cost\"] = t\n",
    "\n",
    "risk_idx = w[\"resource\"]*comp[\"resource\"] + w[\"site_env\"]*comp[\"site_env\"] + w[\"schedule\"]*comp[\"schedule\"] + w[\"cost\"]*comp[\"cost\"]\n",
    "risk_idx = (risk_idx - risk_idx.min())/(risk_idx.max()-risk_idx.min()+1e-9)\n",
    "\n",
    "out = pd.DataFrame({\n",
    "    \"Project_ID\": df[\"Project_ID\"],\n",
    "    \"planning_risk_index\": risk_idx\n",
    "})\n",
    "out[\"health_score_planning\"] = (100*(1 - out[\"planning_risk_index\"])).round().astype(int)\n",
    "out[\"risk_band\"] = pd.cut(out[\"planning_risk_index\"], bins=[0,0.33,0.66,1.0], labels=[\"Low\",\"Medium\",\"High\"], include_lowest=True)\n",
    "\n",
    "out.to_csv(\"planning_risk_index.csv\", index=False)\n",
    "print(\"Saved: planning_risk_index.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c148b8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:41:17.531956Z",
     "iopub.status.busy": "2025-11-01T15:41:17.531675Z",
     "iopub.status.idle": "2025-11-01T15:41:17.611846Z",
     "shell.execute_reply": "2025-11-01T15:41:17.611211Z"
    },
    "papermill": {
     "duration": 0.085216,
     "end_time": "2025-11-01T15:41:17.612886",
     "exception": false,
     "start_time": "2025-11-01T15:41:17.527670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: what_if_grid.json\n",
      "Saved: what_if_examples.csv\n"
     ]
    }
   ],
   "source": [
    "# === Block 4: What-If engine (planning) + examples ===\n",
    "import numpy as np, pandas as pd, json, joblib\n",
    "\n",
    "PATH = \"df_working.csv\"\n",
    "df0 = pd.read_csv(PATH, parse_dates=[\"Start_Date\",\"End_Date\"])\n",
    "\n",
    "bundle = joblib.load(\"brain_planning_component_model.pkl\")   # dict with {\"calibrated_model\": ...}\n",
    "model  = bundle[\"calibrated_model\"]\n",
    "\n",
    "def nzstd_series(s):\n",
    "    s = s.astype(float)\n",
    "    return (s - s.mean())/(s.std()+1e-9)\n",
    "\n",
    "def compute_components(df):\n",
    "    comp = {}\n",
    "    # Resource\n",
    "    t = 0\n",
    "    if \"Labor_Hours\" in df:           t += nzstd_series(df[\"Labor_Hours\"])\n",
    "    if \"Equipment_Utilization\" in df: t += nzstd_series(df[\"Equipment_Utilization\"])\n",
    "    if \"Material_Usage\" in df:        t += nzstd_series(df[\"Material_Usage\"])\n",
    "    comp[\"resource\"] = t\n",
    "\n",
    "    # Site/env\n",
    "    t = 0\n",
    "    for c in [\"Temperature\",\"Humidity\",\"Air_Quality_Index\"]:\n",
    "        if c in df: t += nzstd_series(df[c])\n",
    "    comp[\"site_env\"] = t\n",
    "\n",
    "    # Schedule\n",
    "    t = 0\n",
    "    if \"Planned_Duration\" in df:      t += nzstd_series(df[\"Planned_Duration\"])\n",
    "    if \"Start_Date\" in df.columns:\n",
    "        s = pd.to_datetime(df[\"Start_Date\"], errors=\"coerce\")\n",
    "        t += ((s.dt.month - 6.5)/3.8).fillna(0)\n",
    "    comp[\"schedule\"] = t\n",
    "\n",
    "    # Cost\n",
    "    t = 0\n",
    "    if {\"Planned_Cost\",\"Planned_Duration\"}.issubset(df.columns):\n",
    "        t += nzstd_series(df[\"Planned_Cost\"]/df[\"Planned_Duration\"])\n",
    "    comp[\"cost\"] = t\n",
    "\n",
    "    return pd.DataFrame(comp).fillna(0.0)\n",
    "\n",
    "def predict_prob(COMP):\n",
    "    return model.predict_proba(COMP.values)[:, 1]\n",
    "\n",
    "# Base components + probabilities\n",
    "COMP0   = compute_components(df0)\n",
    "BASE_P  = predict_prob(COMP0)\n",
    "\n",
    "# What-if function\n",
    "def what_if(row_idx, buffer_days=0, delta_utilization=0.0, delta_material_usage=0.0):\n",
    "    df = df0.copy()\n",
    "\n",
    "    if \"Planned_Duration\" in df:\n",
    "        df.loc[row_idx, \"Planned_Duration\"] = max(1, df.loc[row_idx, \"Planned_Duration\"] + buffer_days)\n",
    "    if \"Equipment_Utilization\" in df:\n",
    "        df.loc[row_idx, \"Equipment_Utilization\"] = df.loc[row_idx, \"Equipment_Utilization\"] + delta_utilization\n",
    "    if \"Material_Usage\" in df:\n",
    "        df.loc[row_idx, \"Material_Usage\"] = max(0.0, df.loc[row_idx, \"Material_Usage\"] + delta_material_usage)\n",
    "\n",
    "    COMP = compute_components(df)\n",
    "    p_new  = float(predict_prob(COMP)[row_idx])\n",
    "    p_base = float(BASE_P[row_idx])\n",
    "    return {\"p_base\": p_base, \"p_new\": p_new, \"delta\": p_new - p_base}\n",
    "\n",
    "# Slider grids for FE\n",
    "grid = {\n",
    "    \"buffer_days\": [0, 5, 10, 15],\n",
    "    \"delta_utilization\": [-0.10, 0.0, 0.10],\n",
    "    \"delta_material_usage\": [-50.0, 0.0, 50.0]\n",
    "}\n",
    "json.dump(grid, open(\"what_if_grid.json\",\"w\"), indent=2)\n",
    "print(\"Saved: what_if_grid.json\")\n",
    "\n",
    "# Examples for top-5 highest-risk projects\n",
    "top_idx = np.argsort(-BASE_P)[:5]\n",
    "rows = []\n",
    "for i in top_idx:\n",
    "    pid = df0.loc[i, \"Project_ID\"]\n",
    "    res = what_if(int(i), buffer_days=10, delta_utilization=-0.05, delta_material_usage=-25.0)\n",
    "    rows.append({\"Project_ID\": pid, **res})\n",
    "pd.DataFrame(rows).to_csv(\"what_if_examples.csv\", index=False)\n",
    "print(\"Saved: what_if_examples.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f657dc5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:41:17.618180Z",
     "iopub.status.busy": "2025-11-01T15:41:17.617987Z",
     "iopub.status.idle": "2025-11-01T15:41:17.795976Z",
     "shell.execute_reply": "2025-11-01T15:41:17.795305Z"
    },
    "papermill": {
     "duration": 0.181934,
     "end_time": "2025-11-01T15:41:17.797042",
     "exception": false,
     "start_time": "2025-11-01T15:41:17.615108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: topN_portfolio.json\n",
      "Saved: project_detail.json\n",
      "Saved: slide_top10_table.csv\n"
     ]
    }
   ],
   "source": [
    "# === Block 5: Top-N portfolio JSON, per-project detail JSON, slide table ===\n",
    "import json, pandas as pd, numpy as np\n",
    "\n",
    "scores = pd.read_csv(\"brain_planning_v2_outputs.csv\")\n",
    "weights = json.load(open(\"brain_planning_component_weights.json\"))\n",
    "w = weights[\"component_weights\"]\n",
    "\n",
    "def row_reasons(row, k=3):\n",
    "    contribs = {\n",
    "        \"resource\":  row[\"comp_resource\"]  * w.get(\"resource\", 0.0),\n",
    "        \"site_env\":  row[\"comp_site_env\"]  * w.get(\"site_env\", 0.0),\n",
    "        \"schedule\":  row[\"comp_schedule\"]  * w.get(\"schedule\", 0.0),\n",
    "        \"cost\":      row[\"comp_cost\"]      * w.get(\"cost\", 0.0),\n",
    "    }\n",
    "    ordered = sorted(contribs.items(), key=lambda x: abs(x[1]), reverse=True)[:k]\n",
    "    return [{\"factor\": f, \"contribution\": float(c)} for f, c in ordered]\n",
    "\n",
    "# Top-N portfolio\n",
    "N = 20\n",
    "topN = scores.sort_values(\"p_delay_planning\", ascending=False).head(N).copy()\n",
    "payload = []\n",
    "for _, r in topN.iterrows():\n",
    "    payload.append({\n",
    "        \"project_id\": r[\"Project_ID\"],\n",
    "        \"p_delay\": float(r[\"p_delay_planning\"]),\n",
    "        \"health\": int(r[\"health_score_planning\"]),\n",
    "        \"band\":   str(r[\"risk_band_planning\"]),\n",
    "        \"reasons\": row_reasons(r, k=3)\n",
    "    })\n",
    "with open(\"topN_portfolio.json\", \"w\") as f:\n",
    "    json.dump({\"updated_at\": pd.Timestamp.now().isoformat(), \"items\": payload}, f, indent=2)\n",
    "print(\"Saved: topN_portfolio.json\")\n",
    "\n",
    "# Per-project detail dict (all rows)\n",
    "detail = {}\n",
    "for _, r in scores.iterrows():\n",
    "    pid = str(r[\"Project_ID\"])\n",
    "    detail[pid] = {\n",
    "        \"p_delay\": float(r[\"p_delay_planning\"]),\n",
    "        \"health\":  int(r[\"health_score_planning\"]),\n",
    "        \"band\":    str(r[\"risk_band_planning\"]),\n",
    "        \"components\": {\n",
    "            \"resource\": float(r[\"comp_resource\"]),\n",
    "            \"site_env\": float(r[\"comp_site_env\"]),\n",
    "            \"schedule\": float(r[\"comp_schedule\"]),\n",
    "            \"cost\":     float(r[\"comp_cost\"])\n",
    "        },\n",
    "        \"reasons\": row_reasons(r, k=3)\n",
    "    }\n",
    "with open(\"project_detail.json\", \"w\") as f:\n",
    "    json.dump(detail, f, indent=2)\n",
    "print(\"Saved: project_detail.json\")\n",
    "\n",
    "# Slide-ready Top-10 table\n",
    "top10 = topN.head(10)[[\"Project_ID\",\"p_delay_planning\",\"health_score_planning\",\"risk_band_planning\"]].copy()\n",
    "top10.columns = [\"Project_ID\",\"P_Delay\",\"Health\",\"Band\"]\n",
    "top10.to_csv(\"slide_top10_table.csv\", index=False)\n",
    "print(\"Saved: slide_top10_table.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6d7059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T15:41:17.802301Z",
     "iopub.status.busy": "2025-11-01T15:41:17.802079Z",
     "iopub.status.idle": "2025-11-01T15:41:17.831140Z",
     "shell.execute_reply": "2025-11-01T15:41:17.830399Z"
    },
    "papermill": {
     "duration": 0.033023,
     "end_time": "2025-11-01T15:41:17.832390",
     "exception": false,
     "start_time": "2025-11-01T15:41:17.799367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: PULSE_Brain_Payloads.zip\n"
     ]
    }
   ],
   "source": [
    "# === Block 6: Package artifacts into a zip for FE/demo handoff ===\n",
    "import textwrap, zipfile, os\n",
    "from pathlib import Path\n",
    "\n",
    "files = [\n",
    "    \"brain_planning_v2_outputs.csv\",\n",
    "    \"brain_planning_component_weights.json\",\n",
    "    \"brain_planning_component_model.pkl\",\n",
    "    \"what_if_grid.json\",\n",
    "    \"what_if_examples.csv\",\n",
    "    \"planning_risk_index.csv\",        # from Block 3 (optional overlay)\n",
    "    \"topN_portfolio.json\",\n",
    "    \"project_detail.json\",\n",
    "    \"slide_top10_table.csv\",\n",
    "]\n",
    "\n",
    "readme = textwrap.dedent(\"\"\"\n",
    "    PULSE Brain — Planning Risk (Demo Payloads)\n",
    "\n",
    "    Use these to mock API responses in the FE:\n",
    "    - GET /drivers       -> brain_planning_component_weights.json\n",
    "    - GET /portfolio     -> topN_portfolio.json\n",
    "    - GET /project/:id   -> project_detail.json[\":id\"]\n",
    "    - GET /what-if-grid  -> what_if_grid.json\n",
    "\n",
    "    Core fields:\n",
    "    - p_delay_planning (0..1), Health = round(100 * (1 - p_delay_planning))\n",
    "    - Bands: quantiles over p_delay_planning -> Low/Medium/High\n",
    "    - Reasons: component-based contributions (resource/site_env/schedule/cost)\n",
    "\"\"\").strip()\n",
    "Path(\"README_BRAIN.txt\").write_text(readme, encoding=\"utf-8\")\n",
    "files.append(\"README_BRAIN.txt\")\n",
    "\n",
    "zip_path = \"PULSE_Brain_Payloads.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
    "    for f in files:\n",
    "        if os.path.exists(f):\n",
    "            z.write(f)\n",
    "print(f\"Saved: {zip_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad27c381",
   "metadata": {
    "papermill": {
     "duration": 0.001987,
     "end_time": "2025-11-01T15:41:17.836707",
     "exception": false,
     "start_time": "2025-11-01T15:41:17.834720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6757999,
     "sourceId": 10876711,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7.219472,
   "end_time": "2025-11-01T15:41:18.355263",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-01T15:41:11.135791",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
